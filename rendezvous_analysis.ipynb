{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rendezvous Embedding Dimension Scaling Analysis\n",
    "\n",
    "## Comprehensive Analysis of 20 Core Experiments\n",
    "\n",
    "**Experiment Matrix**: 4 agent counts × 5 embedding dimensions × 1 seed = 20 configurations\n",
    "\n",
    "- **Agent Counts**: [4, 16, 50, 100] - testing from minimal to large swarms\n",
    "- **Embedding Dimensions**: [4, 8, 32, 64, 128] - from information bottleneck to saturation\n",
    "- **Baseline Reference**: d=64 matches Hüttenrauch et al. (2019)\n",
    "\n",
    "This notebook extracts metrics from TensorBoard event files and provides:\n",
    "1. Summary statistics across all 20 configurations\n",
    "2. Performance heatmaps and scaling analysis\n",
    "3. Learning curve comparisons\n",
    "4. Convergence speed analysis\n",
    "5. Comparison to Hüttenrauch baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "\n",
    "# Suppress TensorBoard verbose output\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Event File Discovery and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory for rendezvous experiments\n",
    "BASE_DIR = Path(\"C:/Users/robin/Desktop/Master_Studium/Masterarbeit/MARL-Swarm/logs/rendezvous_embedding\")\n",
    "\n",
    "# Verify directory exists\n",
    "assert BASE_DIR.exists(), f\"Base directory not found: {BASE_DIR}\"\n",
    "\n",
    "# Find all experiment directories\n",
    "exp_dirs = sorted([d for d in BASE_DIR.iterdir() if d.is_dir()])\n",
    "print(f\"Found {len(exp_dirs)} experiment directories\\n\")\n",
    "\n",
    "for d in exp_dirs[:5]:\n",
    "    print(f\"  {d.name}\")\n",
    "print(f\"  ... ({len(exp_dirs)-5} more)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_experiment_name(exp_name):\n",
    "    \"\"\"\n",
    "    Parse experiment name to extract parameters.\n",
    "    Format: num_agents{N}_embed_dim{D}_seed{S}\n",
    "    \"\"\"\n",
    "    parts = exp_name.split('_')\n",
    "    params = {}\n",
    "    \n",
    "    for i, part in enumerate(parts):\n",
    "        if part == 'num' and i+1 < len(parts) and parts[i+1] == 'agents':\n",
    "            params['num_agents'] = int(parts[i+2])\n",
    "        elif part == 'embed' and i+1 < len(parts) and parts[i+1] == 'dim':\n",
    "            params['embed_dim'] = int(parts[i+2])\n",
    "        elif part == 'seed':\n",
    "            params['seed'] = int(parts[i+1])\n",
    "    \n",
    "    return params\n",
    "\n",
    "# Test parser\n",
    "test_name = \"num_agents4_embed_dim64_seed0\"\n",
    "print(f\"Test parse: {test_name}\")\n",
    "print(f\"Result: {parse_experiment_name(test_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_event_file(event_path):\n",
    "    \"\"\"\n",
    "    Load a single TensorBoard event file and extract scalar metrics.\n",
    "    Returns dictionary of metric_name -> list of (step, value) tuples\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ea = EventAccumulator(str(event_path))\n",
    "        ea.Reload()\n",
    "        \n",
    "        metrics = {}\n",
    "        \n",
    "        # Get all available scalar keys\n",
    "        scalar_keys = ea.Tags()['scalars']\n",
    "        \n",
    "        for key in scalar_keys:\n",
    "            try:\n",
    "                events = ea.Scalars(key)\n",
    "                # Convert to array for easier processing\n",
    "                values = np.array([e.value for e in events])\n",
    "                steps = np.array([e.step for e in events])\n",
    "                metrics[key] = {'steps': steps, 'values': values, 'events': events}\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        return metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {event_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test loading a single event file\n",
    "test_exp = exp_dirs[0]\n",
    "trpo_dir = list(test_exp.glob(\"TRPO_*\"))[0]\n",
    "event_file = list(trpo_dir.glob(\"events.out.tfevents*\"))[0]\n",
    "\n",
    "print(f\"Loading: {test_exp.name}\")\n",
    "metrics = load_event_file(event_file)\n",
    "\n",
    "if metrics:\n",
    "    print(f\"\\nFound {len(metrics)} metric keys:\")\n",
    "    for key in sorted(metrics.keys())[:10]:\n",
    "        n_samples = len(metrics[key]['values'])\n",
    "        print(f\"  {key}: {n_samples} samples\")\n",
    "    if len(metrics) > 10:\n",
    "        print(f\"  ... and {len(metrics)-10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comprehensive Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_summary_stats(metrics_dict, key_patterns):\n",
    "    \"\"\"\n",
    "    Extract key statistics from metrics.\n",
    "    \n",
    "    Args:\n",
    "        metrics_dict: Dictionary of metrics from load_event_file\n",
    "        key_patterns: List of metric key names to look for\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with summary statistics\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "    \n",
    "    if metrics_dict is None:\n",
    "        return stats\n",
    "    \n",
    "    for pattern in key_patterns:\n",
    "        # Find matching keys (case-insensitive)\n",
    "        matching_keys = [k for k in metrics_dict.keys() if pattern.lower() in k.lower()]\n",
    "        \n",
    "        if matching_keys:\n",
    "            # Use first match (usually most relevant)\n",
    "            key = matching_keys[0]\n",
    "            values = metrics_dict[key]['values']\n",
    "            steps = metrics_dict[key]['steps']\n",
    "            \n",
    "            if len(values) > 0:\n",
    "                stats[f'{pattern}_final'] = float(values[-1])\n",
    "                stats[f'{pattern}_max'] = float(np.max(values))\n",
    "                stats[f'{pattern}_min'] = float(np.min(values))\n",
    "                stats[f'{pattern}_mean'] = float(np.mean(values))\n",
    "                stats[f'{pattern}_std'] = float(np.std(values))\n",
    "                stats[f'{pattern}_n_steps'] = len(values)\n",
    "                \n",
    "                # Convergence iteration (80% of max improvement)\n",
    "                if np.min(values) != np.max(values):\n",
    "                    target = np.min(values) + 0.8 * (np.max(values) - np.min(values))\n",
    "                    convergence_idx = np.argmax(values >= target)\n",
    "                    if convergence_idx > 0:\n",
    "                        stats[f'{pattern}_converge_iter'] = int(steps[convergence_idx])\n",
    "    \n",
    "    return stats\n",
    "\n",
    "print(\"Defined extract_summary_stats function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics from all experiments\nresults = []\nerrors = []\n\nfor exp_dir in exp_dirs:\n    try:\n        # Parse experiment parameters\n        params = parse_experiment_name(exp_dir.name)\n        \n        # Find TRPO directory\n        trpo_dirs = list(exp_dir.glob(\"TRPO_*\"))\n        if not trpo_dirs:\n            errors.append(f\"{exp_dir.name}: No TRPO directory found\")\n            continue\n        \n        # Find event file\n        event_files = list(trpo_dirs[0].glob(\"events.out.tfevents*\"))\n        if not event_files:\n            errors.append(f\"{exp_dir.name}: No event file found\")\n            continue\n        \n        # Load metrics\n        metrics = load_event_file(event_files[0])\n        if metrics is None:\n            errors.append(f\"{exp_dir.name}: Failed to load event file\")\n            continue\n        \n        # Extract summary statistics\n        # Look for common TRPO metric names\n        stats = extract_summary_stats(metrics, [\n            'rollout/ep_rew',\n            'rollout/ep_len',\n            'train/policy_loss',\n            'train/value_loss',\n            'train/entropy_loss',\n            'train/approxkl',\n            'rollout/success'\n        ])\n        \n        # Combine parameters and statistics\n        record = {**params, **stats, 'exp_name': exp_dir.name}\n        results.append(record)\n        \n    except Exception as e:\n        errors.append(f\"{exp_dir.name}: {str(e)}\")\n\nprint(f\"\\nSuccessfully loaded: {len(results)} experiments\")\nif errors:\n    print(f\"Errors encountered: {len(errors)}\")\n    for err in errors[:5]:\n        print(f\"  - {err}\")\n\ndf = pd.DataFrame(results)\nprint(f\"\\nDataFrame shape: {df.shape}\")\nprint(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary of loaded data\nprint(\"=\"*80)\nprint(\"EXPERIMENT PARAMETERS\")\nprint(\"=\"*80)\nprint(f\"\\nAgent counts: {sorted(df['num_agents'].unique())}\")\nprint(f\"Embedding dims: {sorted(df['embed_dim'].unique())}\")\nprint(f\"Seeds: {sorted(df['seed'].unique())}\")\nprint(f\"\\nTotal configurations: {len(df)}\")\n\n# Show first few rows\nprint(\"\\n\" + \"=\"*80)\nprint(\"FIRST FEW EXPERIMENTS\")\nprint(\"=\"*80)\ndisplay_cols = ['exp_name', 'num_agents', 'embed_dim', 'rollout/ep_rew_final', 'rollout/ep_len_final']\navailable_cols = [c for c in display_cols if c in df.columns]\nprint(df[available_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary Statistics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary table\nsummary_df = df[['exp_name', 'num_agents', 'embed_dim', 'seed']].copy()\n\n# Add performance metrics (use available columns)\nperformance_cols = [c for c in df.columns if 'ep_rew' in c or 'ep_len' in c]\n\nfor col in performance_cols[:4]:  # Limit to top 4 to avoid clutter\n    if col in df.columns:\n        summary_df[col.replace('rollout/', '')] = df[col].round(2)\n\n# Sort by reward (descending)\nif 'ep_rew_final' in summary_df.columns:\n    summary_df = summary_df.sort_values('ep_rew_final', ascending=False, na_position='last')\nelif 'ep_rew_mean' in summary_df.columns:\n    summary_df = summary_df.sort_values('ep_rew_mean', ascending=False, na_position='last')\n\nprint(\"=\"*100)\nprint(\"COMPLETE EXPERIMENT SUMMARY TABLE (Sorted by Final Reward)\")\nprint(\"=\"*100)\nprint()\ndisplay(summary_df.head(20))\n\nprint(f\"\\nFull table available: {len(summary_df)} rows × {len(summary_df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify key metrics to use throughout analysis\nif 'rollout/ep_rew_final' in df.columns:\n    reward_col = 'rollout/ep_rew_final'\nelif 'rollout/ep_rew_mean' in df.columns:\n    reward_col = 'rollout/ep_rew_mean'\nelse:\n    reward_col = [c for c in df.columns if 'ep_rew' in c][0] if any('ep_rew' in c for c in df.columns) else None\n\nif 'rollout/ep_len_final' in df.columns:\n    length_col = 'rollout/ep_len_final'\nelif 'rollout/ep_len_mean' in df.columns:\n    length_col = 'rollout/ep_len_mean'\nelse:\n    length_col = [c for c in df.columns if 'ep_len' in c][0] if any('ep_len' in c for c in df.columns) else None\n\nprint(f\"Selected reward metric: {reward_col}\")\nprint(f\"Selected length metric: {length_col}\")\n\nif reward_col:\n    print(f\"\\nReward statistics:\")\n    print(f\"  Mean: {df[reward_col].mean():.3f}\")\n    print(f\"  Std:  {df[reward_col].std():.3f}\")\n    print(f\"  Min:  {df[reward_col].min():.3f}\")\n    print(f\"  Max:  {df[reward_col].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Heatmap Analysis: Performance vs Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of final rewards\nif reward_col:\n    # Pivot table: num_agents (rows) x embed_dim (columns)\n    heatmap_data = df.pivot_table(\n        values=reward_col,\n        index='num_agents',\n        columns='embed_dim',\n        aggfunc='mean'\n    )\n    \n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Heatmap 1: Absolute rewards\n    ax = axes[0]\n    sns.heatmap(heatmap_data, annot=True, fmt='.2f', cmap='RdYlGn', ax=ax,\n                cbar_kws={'label': 'Final Reward'})\n    ax.set_title('Final Reward Heatmap\\n(Agent Count × Embedding Dimension)', fontsize=12, fontweight='bold')\n    ax.set_xlabel('Embedding Dimension', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Number of Agents', fontsize=11, fontweight='bold')\n    \n    # Heatmap 2: Normalized rewards (per row)\n    ax = axes[1]\n    heatmap_normalized = heatmap_data.div(heatmap_data.max(axis=1), axis=0)\n    sns.heatmap(heatmap_normalized, annot=True, fmt='.2f', cmap='YlOrRd', ax=ax,\n                cbar_kws={'label': 'Normalized Performance'})\n    ax.set_title('Normalized Performance (Best=1.0)\\n(Agent Count × Embedding Dimension)', fontsize=12, fontweight='bold')\n    ax.set_xlabel('Embedding Dimension', fontsize=11, fontweight='bold')\n    ax.set_ylabel('Number of Agents', fontsize=11, fontweight='bold')\n    \n    plt.tight_layout()\n    plt.savefig('rendezvous_heatmaps.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    print(\"Heatmap visualization saved as 'rendezvous_heatmaps.png'\")\nelse:\n    print(\"No reward column found for heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dimensional Reduction Analysis (Embedding Dim × Performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reward_col:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    agent_counts = sorted(df['num_agents'].unique())\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(agent_counts)))\n",
    "    \n",
    "    for idx, n_agents in enumerate(agent_counts):\n",
    "        ax = axes[idx // 2, idx % 2]\n",
    "        \n",
    "        subset = df[df['num_agents'] == n_agents].sort_values('embed_dim')\n",
    "        \n",
    "        # Plot line\n",
    "        ax.plot(subset['embed_dim'], subset[reward_col], 'o-',\n",
    "               linewidth=2.5, markersize=8, color=colors[idx], label=f'N={n_agents}')\n",
    "        \n",
    "        # Highlight baseline (embed_dim=64)\n",
    "        baseline = subset[subset['embed_dim'] == 64]\n",
    "        if not baseline.empty:\n",
    "            baseline_reward = baseline[reward_col].values[0]\n",
    "            ax.scatter(64, baseline_reward, s=300, marker='s', color='red',\n",                    edgecolor='darkred', linewidth=2, label='Baseline (d=64)', zorder=5)\n",
    "        \n",
    "        ax.set_xlabel('Embedding Dimension', fontsize=11, fontweight='bold')\n",
    "        ax.set_ylabel('Final Reward', fontsize=11, fontweight='bold')\n",
    "        ax.set_title(f'Performance Scaling: {n_agents} Agents', fontsize=12, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(loc='best')\n",
    "        ax.set_xticks([4, 8, 32, 64, 128])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('dimensional_reduction_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Dimensional reduction analysis saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scalability Analysis (Swarm Size × Performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reward_col:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    embed_dims = sorted(df['embed_dim'].unique())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(embed_dims)))\n",
    "    \n",
    "    # Plot 1: Separate lines for each embedding dimension\n",
    "    ax = axes[0]\n",
    "    for idx, d in enumerate(embed_dims):\n",
    "        subset = df[df['embed_dim'] == d].sort_values('num_agents')\n",
    "        ax.plot(subset['num_agents'], subset[reward_col], 'o-',\n",
    "               linewidth=2.5, markersize=8, label=f'd={d}', color=colors[idx])\n",
    "    \n",
    "    ax.set_xlabel('Number of Agents', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Final Reward', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Scalability: Reward vs Swarm Size', fontsize=12, fontweight='bold')\n",
    "    ax.set_xscale('log')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    \n",
    "    # Plot 2: Performance delta vs baseline (d=64)\n",
    "    ax = axes[1]\n",
    "    baseline_df = df[df['embed_dim'] == 64].copy()\n",
    "    baseline_dict = dict(zip(baseline_df['num_agents'], baseline_df[reward_col]))\n",
    "    \n",
    "    for idx, d in enumerate(embed_dims):\n",
    "        subset = df[df['embed_dim'] == d].sort_values('num_agents')\n",
    "        deltas = []\n",
    "        for _, row in subset.iterrows():\n",
    "            baseline = baseline_dict.get(row['num_agents'])\n",
    "            if baseline is not None:\n",
    "                delta = (row[reward_col] - baseline) / abs(baseline) * 100 if baseline != 0 else 0\n",
    "                deltas.append(delta)\n",
    "        \n",
    "        if deltas:\n",
    "            ax.plot(subset['num_agents'], deltas, 'o-',\n",
    "                   linewidth=2.5, markersize=8, label=f'd={d}', color=colors[idx])\n",
    "    \n",
    "    ax.axhline(y=0, color='k', linestyle='--', linewidth=1, alpha=0.5, label='Baseline')\n",
    "    ax.set_xlabel('Number of Agents', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Performance Delta (% vs d=64)', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Relative Performance: Comparison to Hüttenrauch Baseline', fontsize=12, fontweight='bold')\n",
    "    ax.set_xscale('log')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('scalability_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Scalability analysis saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Learning Curves: Representative Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_metrics(exp_name):\n",
    "    \"\"\"\n",
    "    Get full metric time series for an experiment.\n",
    "    \"\"\"\n",
    "    exp_dir = BASE_DIR / exp_name\n",
    "    trpo_dirs = list(exp_dir.glob(\"TRPO_*\"))\n",
    "    if not trpo_dirs:\n",
    "        return None\n",
    "    \n",
    "    event_files = list(trpo_dirs[0].glob(\"events.out.tfevents*\"))\n",
    "    if not event_files:\n",
    "        return None\n",
    "    \n",
    "    return load_event_file(event_files[0])\n",
    "\n",
    "# Select representative configurations\n",
    "# Strategy: For each agent count, select d=4, d=32, d=64 (baseline), d=128\nconfigs_to_plot = []\nagent_counts = sorted(df['num_agents'].unique())\n\nfor n_agents in agent_counts[:2]:  # Just show 2 agent counts to avoid clutter\n    for d in [4, 32, 64, 128]:\n",
    "        subset = df[(df['num_agents'] == n_agents) & (df['embed_dim'] == d)]\n",
    "        if not subset.empty:\n",
    "            exp_name = subset.iloc[0]['exp_name']\n",
    "            configs_to_plot.append((n_agents, d, exp_name))\n",
    "\nprint(f\"Selected {len(configs_to_plot)} configurations for learning curve plots:\")\nfor n, d, exp in configs_to_plot:\n",
    "    print(f\"  N={n}, d={d}: {exp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\nfor idx, (n_agents, d, exp_name) in enumerate(configs_to_plot[:4]):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    metrics = get_full_metrics(exp_name)\n",
    "    \n",
    "    if metrics and reward_col:\n",
    "        # Find reward metric\n",
    "        reward_keys = [k for k in metrics.keys() if 'ep_rew' in k]\n",
    "        if reward_keys:\n",
    "            key = reward_keys[0]\n",
    "            steps = metrics[key]['steps']\n",
    "            values = metrics[key]['values']\n",
    "            \n",
    "            # Plot with smoothing\n",
    "            ax.plot(steps, values, alpha=0.3, color='steelblue', label='Raw')\n",
    "            \n",
    "            # Exponential moving average\n",
    "            if len(values) > 1:\n",
    "                ema = pd.Series(values).ewm(span=max(5, len(values)//20)).mean()\n",
    "                ax.plot(steps, ema, linewidth=2.5, color='darkblue', label='EMA')\n",
    "            \n",
    "            ax.set_xlabel('Training Step', fontsize=10, fontweight='bold')\n",
    "            ax.set_ylabel('Episode Reward', fontsize=10, fontweight='bold')\n",
    "            ax.set_title(f'N={n_agents} agents, d={d} embedding', fontsize=11, fontweight='bold')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            ax.legend(loc='best')\n",
    "            \n",
    "            # Add convergence info\n",
    "            final_reward = values[-1]\n",
    "            ax.text(0.98, 0.05, f'Final: {final_reward:.2f}',\n",
    "                   transform=ax.transAxes, fontsize=10,\n",
    "                   verticalalignment='bottom', horizontalalignment='right',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f'No data for\\nN={n_agents}, d={d}',\n",
    "               ha='center', va='center', transform=ax.transAxes)\n",
    "\nplt.tight_layout()\nplt.savefig('learning_curves_representative.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"Learning curves saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Embedding Dimension Saturation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reward_col:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    agent_counts = sorted(df['num_agents'].unique())\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(agent_counts)))\n",
    "    \n",
    "    # Axis 1: Improvement from minimum to maximum embedding\n",
    "    ax = axes[0, 0]\n",
    "    improvements = []\n",
    "    for n_agents in agent_counts:\n",
    "        subset = df[df['num_agents'] == n_agents].sort_values('embed_dim')\n",
    "        min_reward = subset[reward_col].min()\n",
    "        max_reward = subset[reward_col].max()\n",
    "        improvement = max_reward - min_reward\n",
    "        improvements.append(improvement)\n",
    "    \n",
    "    ax.bar(range(len(agent_counts)), improvements, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax.set_xticks(range(len(agent_counts)))\n",
    "    ax.set_xticklabels([f'N={n}' for n in agent_counts])\n",
    "    ax.set_ylabel('Reward Improvement', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Embedding Dimension Impact\\n(Max Reward - Min Reward)', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Axis 2: Reward per unit embedding dimension (efficiency)\n",
    "    ax = axes[0, 1]\n",
    "    for idx, n_agents in enumerate(agent_counts):\n",
    "        subset = df[df['num_agents'] == n_agents].sort_values('embed_dim')\n",
    "        efficiency = subset[reward_col] / (subset['embed_dim'] / 64.0)  # Normalize to baseline\n",
    "        ax.plot(subset['embed_dim'], efficiency, 'o-', linewidth=2, markersize=8,\n",
    "               color=colors[idx], label=f'N={n_agents}')\n",
    "    \n",
    "    ax.set_xlabel('Embedding Dimension', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Efficiency (Reward per Norm. Dim)', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Embedding Efficiency Curve', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_xticks([4, 8, 32, 64, 128])\n",
    "    \n",
    "    # Axis 3: Saturation ratio (high-dim vs baseline)\n",
    "    ax = axes[1, 0]\n",
    "    ratios = []\n",
    "    for n_agents in agent_counts:\n",
    "        d4 = df[(df['num_agents'] == n_agents) & (df['embed_dim'] == 4)][reward_col].values\n",
    "        d64 = df[(df['num_agents'] == n_agents) & (df['embed_dim'] == 64)][reward_col].values\n",
    "        d128 = df[(df['num_agents'] == n_agents) & (df['embed_dim'] == 128)][reward_col].values\n",
    "        \n",
    "        if len(d4) > 0 and len(d64) > 0 and len(d128) > 0:\n",
    "            ratio_4_64 = d4[0] / d64[0]\n",
    "            ratio_128_64 = d128[0] / d64[0]\n",
    "            ratios.append({'agent_count': n_agents, 'd4/d64': ratio_4_64, 'd128/d64': ratio_128_64})\n",
    "    \n",
    "    if ratios:\n",
    "        ratio_df = pd.DataFrame(ratios)\n",
    "        x = np.arange(len(ratio_df))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax.bar(x - width/2, ratio_df['d4/d64'], width, label='d=4 / d=64', alpha=0.8, color='coral')\n",
    "        ax.bar(x + width/2, ratio_df['d128/d64'], width, label='d=128 / d=64', alpha=0.8, color='lightgreen')\n",
    "        \n",
    "        ax.axhline(y=1.0, color='red', linestyle='--', linewidth=2, label='Baseline (d=64)')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([f'N={n}' for n in ratio_df['agent_count']])\n",
    "        ax.set_ylabel('Performance Ratio', fontsize=11, fontweight='bold')\n",
    "        ax.set_title('Relative Performance vs Hüttenrauch Baseline', fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Axis 4: Summary statistics table\n",
    "    ax = axes[1, 1]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Create statistics table\n",
    "    table_data = []\n",
    "    for n_agents in agent_counts:\n",
    "        subset = df[df['num_agents'] == n_agents]\n",
    "        table_data.append([\n",
    "            f'N={n_agents}',\n",
    "            f\"{subset[reward_col].min():.2f}\",\n",
    "            f\"{subset[reward_col].max():.2f}\",\n",
    "            f\"{subset[reward_col].mean():.2f}\"\n",
    "        ])\n",
n",
    "    table = ax.table(cellText=table_data,\n",
    "                    colLabels=['Agents', 'Min Reward', 'Max Reward', 'Mean Reward'],\n",
    "                    cellLoc='center', loc='center',\n",
    "                    colWidths=[0.2, 0.25, 0.25, 0.25])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # Style header\n",
    "    for i in range(4):\n",
    "        table[(0, i)].set_facecolor('#40466e')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    ax.set_title('Performance Summary by Agent Count', fontsize=12, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('saturation_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Saturation analysis saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Convergence Speed Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_convergence_metrics(metrics_dict, reward_key, threshold_pct=0.8):\n",
    "    \"\"\"\n",
    "    Compute convergence iteration and speed.\n",
    "    threshold_pct: percentage of final improvement to reach convergence\n",
    "    \"\"\"\n",
    "    if metrics_dict is None or reward_key not in metrics_dict:\n",
    "        return {}\n",
    "    \n",
    "    values = metrics_dict[reward_key]['values']\n",
    "    steps = metrics_dict[reward_key]['steps']\n",
    "    \n",
    "    if len(values) < 2:\n",
    "        return {}\n",
    "    \n",
    "    # Compute improvement from start to end\n",
    "    start_val = values[0]\n",
    "    end_val = values[-1]\n",
    "    improvement = end_val - start_val\n",
    "    \n",
    "    if improvement == 0:\n",
    "        return {'final_reward': end_val, 'total_steps': steps[-1], 'converge_step': steps[-1]}\n",
    "    \n",
    "    # Find step where threshold% of improvement is reached\n",
    "    target = start_val + threshold_pct * improvement\n",
    "    converged_idx = np.argmax(values >= target)\n",
    "    \n",
    "    converge_step = steps[converged_idx] if converged_idx > 0 else steps[-1]\n",
    "    \n",
    "    return {\n",
    "        'final_reward': end_val,\n",
    "        'total_steps': steps[-1],\n",
    "        'converge_step': converge_step,\n",
    "        'convergence_pct': (converge_step / steps[-1] * 100) if steps[-1] > 0 else 100\n",
    "    }\n",
    "\nprint(\"Defined convergence metrics function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute convergence metrics for all experiments\nconvergence_results = []\n\nfor _, row in df.iterrows():\n",
    "    metrics = get_full_metrics(row['exp_name'])\n",
    "    conv_metrics = compute_convergence_metrics(metrics, \n",
    "                                               [k for k in metrics.keys() if 'ep_rew' in k][0] if metrics and any('ep_rew' in k for k in metrics.keys()) else None)\n",
    "    \n",
    "    conv_record = {\n",
    "        'exp_name': row['exp_name'],\n",
    "        'num_agents': row['num_agents'],\n",
    "        'embed_dim': row['embed_dim'],\n",
    "        **conv_metrics\n",
    "    }\n",
    "    convergence_results.append(conv_record)\n",
    "\nconv_df = pd.DataFrame(convergence_results)\n\nif 'converge_step' in conv_df.columns:\n",
    "    print(\"Convergence metrics computed successfully\")\n",
    "    print(f\"\\nConvergence statistics:\")\n",
    "    print(conv_df[['num_agents', 'embed_dim', 'final_reward', 'total_steps', 'converge_step']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'convergence_pct' in conv_df.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    agent_counts = sorted(conv_df['num_agents'].unique())\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, 5))\n",
    "    \n",
    "    # Plot 1: Convergence speed by embedding dimension\n",
    "    ax = axes[0]\n",
    "    for idx, n_agents in enumerate(agent_counts):\n",
    "        subset = conv_df[conv_df['num_agents'] == n_agents].sort_values('embed_dim')\n",
    "        ax.plot(subset['embed_dim'], subset['convergence_pct'], 'o-',\n",
    "               linewidth=2.5, markersize=8, label=f'N={n_agents}')\n",
    "    \n",
    "    ax.set_xlabel('Embedding Dimension', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Training % to Convergence', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Convergence Speed: How Early Does Learning Saturate?', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_xticks([4, 8, 32, 64, 128])\n",
    "    \n",
    "    # Plot 2: Convergence step count (absolute)\n",
    "    ax = axes[1]\n",
    "    for idx, n_agents in enumerate(agent_counts):\n",
    "        subset = conv_df[conv_df['num_agents'] == n_agents].sort_values('embed_dim')\n",
    "        ax.plot(subset['embed_dim'], subset['converge_step'], 'o-',\n",
    "               linewidth=2.5, markersize=8, label=f'N={n_agents}')\n",
    "    \n",
    "    ax.set_xlabel('Embedding Dimension', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Steps to Convergence (80% of improvement)', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Absolute Convergence Speed', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_xticks([4, 8, 32, 64, 128])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('convergence_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Convergence analysis saved\")\nelse:\n",
    "    print(\"Convergence metrics not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Findings and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*100)\nprint(\"KEY FINDINGS: RENDEZVOUS EMBEDDING SCALING ANALYSIS\")\nprint(\"=\"*100)\nprint()\n\nif reward_col:\n    # Finding 1: Best overall configuration\n    best_idx = df[reward_col].idxmax()\n    best_config = df.loc[best_idx]\n",
    "    print(f\"1. BEST OVERALL CONFIGURATION\")\n",
    "    print(f\"   Agents: {int(best_config['num_agents'])}\")\n",
    "    print(f\"   Embedding Dimension: {int(best_config['embed_dim'])}\")\n",
    "    print(f\"   Final Reward: {best_config[reward_col]:.3f}\")\n",
    "    print()\n",
    "    \n",
    "    # Finding 2: Worst configuration\n",
    "    worst_idx = df[reward_col].idxmin()\n",
    "    worst_config = df.loc[worst_idx]\n",
    "    print(f\"2. WORST OVERALL CONFIGURATION\")\n",
    "    print(f\"   Agents: {int(worst_config['num_agents'])}\")\n",
    "    print(f\"   Embedding Dimension: {int(worst_config['embed_dim'])}\")\n",
    "    print(f\"   Final Reward: {worst_config[reward_col]:.3f}\")\n",
    "    print()\n",
    "    \n",
    "    # Finding 3: Baseline (d=64) comparison\n",
    "    baseline_df = df[df['embed_dim'] == 64].copy()\n",
    "    print(f\"3. HÜTTENRAUCH BASELINE (d=64) PERFORMANCE\")\n",
    "    print(f\"   Mean Reward: {baseline_df[reward_col].mean():.3f}\")\n",
    "    print(f\"   Std Dev: {baseline_df[reward_col].std():.3f}\")\n",
    "    print(f\"   Range: [{baseline_df[reward_col].min():.3f}, {baseline_df[reward_col].max():.3f}]\")\n",
    "    print()\n",
    "    \n",
    "    # Finding 4: Embedding dimension saturation\n",
    "    print(f\"4. EMBEDDING DIMENSION SATURATION\")\n",
    "    embed_stats = df.groupby('embed_dim')[reward_col].agg(['mean', 'std', 'min', 'max'])\n",
    "    print(embed_stats.round(3))\n",
    "    print()\n",
    "    \n",
    "    # Finding 5: Agent count scaling\n",
    "    print(f\"5. AGENT COUNT SCALING\")\n",
    "    agent_stats = df.groupby('num_agents')[reward_col].agg(['mean', 'std', 'min', 'max'])\n",
    "    print(agent_stats.round(3))\n",
    "    print()\n",
    "    \n",
    "    # Finding 6: Optimal embedding for each agent count\n",
    "    print(f\"6. OPTIMAL EMBEDDING DIMENSION FOR EACH AGENT COUNT\")\n",
    "    for n_agents in sorted(df['num_agents'].unique()):\n",
    "        subset = df[df['num_agents'] == n_agents]\n",
    "        optimal = subset.loc[subset[reward_col].idxmax()]\n",
    "        baseline = subset[subset['embed_dim'] == 64]\n",
    "        if not baseline.empty:\n",
    "            baseline_reward = baseline[reward_col].values[0]\n",
    "            pct_diff = (optimal[reward_col] - baseline_reward) / abs(baseline_reward) * 100\n",
    "            print(f\"   N={int(n_agents):3d}: d={int(optimal['embed_dim']):3d} \"\n",
    "                  f\"(reward={optimal[reward_col]:7.3f}, {pct_diff:+.1f}% vs baseline)\")\n",
    "        else:\n",
    "            print(f\"   N={int(n_agents):3d}: d={int(optimal['embed_dim']):3d} (reward={optimal[reward_col]:7.3f})\")\n",
    "else:\n",
    "    print(\"No reward column available for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Preliminary Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insights = \"\"\"\n",
    "================================================================================\n",
    "PRELIMINARY INSIGHTS: RENDEZVOUS EMBEDDING SCALING EXPERIMENTS\n",
    "================================================================================\n",
    "\n",
    "A. EMBEDDING DIMENSION INSIGHTS\n",
    "---\n",
    "1. Information Bottleneck (d=4):\n",
    "   - Severely constrains agent perception of swarm state\n",
    "   - Only 4 values to compress neighbor positions/velocities\n",
    "   - Expected poor performance especially at larger swarm sizes\n",
    "\n",
    "2. Low-Dimensional Regime (d=8, 32):\n",
    "   - Tests the hypothesis that mean embeddings work at reduced dimensionality\n",
    "   - Should show clear saturation curve if dimensionality is sufficient\n",
    "   - More practical for embedded systems deployment\n",
    "\n",
    "3. Baseline Anchor (d=64):\n",
    "   - Matches Hüttenrauch et al. (2019) exactly\n",
    "   - Reference point for understanding dimensional reduction benefits\n",
    "   - Should show stable convergence across agent counts\n",
    "\n",
    "4. High-Dimensional (d=128):\n",
    "   - Tests saturation hypothesis (diminishing returns)\n",
    "   - If d=128 ≈ d=64, suggests information bottleneck at ~64 dims\n",
    "   - If d=128 > d=64, suggests underparameterization at baseline\n",
    "\n",
    "B. AGENT COUNT SCALING INSIGHTS\n",
    "---\n",
    "1. N=4 (Lower Bound):\n",
    "   - Trivial case: only 3 neighbors to aggregate\n",
    "   - Expected: high performance even with d=4\n",
    "   - Tests mean embedding at minimal neighbor set\n",
    "\n",
    "2. N=16 (First Significant Test):\n",
    "   - ~15 neighbors per agent\n",
    "   - First test of mean embedding properties beyond toy domain\n",
    "   - 4x increase from N=4\n",
    "\n",
    "3. N=50 (Training Swarm Size):\n",
    "   - Close to Hüttenrauch baseline size (N=20)\n",
    "   - 2.5x baseline scale\n",
    "   - ~49 neighbors per agent\n",
    "\n",
    "4. N=100 (Maximum Stress Test):\n",
    "   - 5x baseline scale\n",
    "   - 99 neighbors per agent\n",
    "   - Tests scalability at edge of max_agents parameter\n",
    "   - Expected: degradation if mean embedding doesn't scale well\n",
    "\n",
    "C. PERFORMANCE EXPECTATIONS vs OBSERVATIONS\n",
    "---\n",
    "If results match theory:\n",
    "  ✓ d=64 should outperform d=4, d=8 across most agent counts\n",
    "  ✓ d=128 should be similar to d=64 (saturation)\n",
    "  ✓ Performance should degrade gracefully from d=4 to d=32\n",
    "  ✓ Larger agent counts should show larger gaps (d=4 vs d=64)\n",
    "\n",
    "If results differ:\n",
    "  ✗ Large performance gap (d=128 >> d=64): baseline underspecified\n",
    "  ✗ d=4 competitive with d=64: information bottleneck is too shallow\n",
    "  ✗ No scaling effect: hyperparameters may override dimensional effects\n",
    "\n",
    "D. HÜTTENRAUCH BASELINE COMPARISON\n",
    "---\n",
    "This analysis uses exactly the same configuration as Hüttenrauch et al.:\n",
    "  - Mean embedding aggregation\n",
    "  - TRPO algorithm\n",
    "  - ReLU activation\n",
    "  - But with VARIABLE embedding dimension (not fixed at 64)\n",
    "\n",
    "Key questions:\n",
    "  1. Can we reduce d from 64 and still match baseline performance?\n",
    "  2. At what embedding dimension do we see quality degradation?\n",
    "  3. How does swarm size interact with optimal embedding dimension?\n",
    "\n",
    "E. PRACTICAL IMPLICATIONS FOR THESIS\n",
    "---\n",
    "1. Deployment Efficiency:\n",
    "   - Smaller d = faster neural network inference\n",
    "   - Critical for real-time swarm control\n",
    "   - Memory footprint scales with embedding dimension\n",
    "\n",
    "2. Generalization:\n",
    "   - Reduced dimensions may improve generalization to unseen swarm sizes\n",
    "   - Information bottleneck acts as regularization\n",
    "\n",
    "3. Communication Bandwidth:\n",
    "   - If agents communicate embeddings, smaller d = lower bandwidth\n",
    "   - Important for multi-robot systems with limited network capacity\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\nprint(insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Complete Results Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary table\nif reward_col:\n",
    "    summary_complete = df[['exp_name', 'num_agents', 'embed_dim', reward_col]].copy()\n",
    "    summary_complete.columns = ['Experiment', 'Agents', 'Embedding Dim', 'Final Reward']\n",
    "    summary_complete = summary_complete.sort_values('Final Reward', ascending=False)\n",
    "    \n",
    "    # Add ranking\n",
    "    summary_complete['Rank'] = range(1, len(summary_complete) + 1)\n",
    "    summary_complete = summary_complete[['Rank', 'Agents', 'Embedding Dim', 'Final Reward', 'Experiment']]\n",
    "    \n",
    "    print(\"=\"*110)\n",
    "    print(\"COMPLETE RANKING: ALL 20 CONFIGURATIONS (Sorted by Final Reward)\")\n",
    "    print(\"=\"*110)\n",
    "    print()\n",
    "    \n",
    "    # Display with better formatting\n",
    "    for idx, row in summary_complete.iterrows():\n",
    "        print(f\"{int(row['Rank']):2d}. N={int(row['Agents']):3d}, d={int(row['Embedding Dim']):3d} | \"\n",
    "              f\"Reward: {row['Final Reward']:8.3f} | {row['Experiment']}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\"*110)\n",
    "    print(\"SUMMARY STATISTICS\")\n",
    "    print(\"=\"*110)\n",
    "    print(f\"\\nTotal Configurations Analyzed: {len(summary_complete)}\")\n",
    "    print(f\"Mean Final Reward: {summary_complete['Final Reward'].mean():.3f}\")\n",
    "    print(f\"Std Dev: {summary_complete['Final Reward'].std():.3f}\")\n",
    "    print(f\"Best: {summary_complete['Final Reward'].max():.3f}\")\n",
    "    print(f\"Worst: {summary_complete['Final Reward'].min():.3f}\")\n",
    "    print(f\"Range: {summary_complete['Final Reward'].max() - summary_complete['Final Reward'].min():.3f}\")\n",
    "else:\n",
    "    print(\"No reward data available for summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Export Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export detailed results\noutput_csv = 'rendezvous_scaling_results.csv'\ndf.to_csv(output_csv, index=False)\nprint(f\"Results exported to: {output_csv}\")\n\n# Export convergence analysis\nif 'converge_step' in conv_df.columns:\n",
    "    conv_csv = 'rendezvous_convergence_analysis.csv'\n",
    "    conv_df.to_csv(conv_csv, index=False)\n",
    "    print(f\"Convergence analysis exported to: {conv_csv}\")\n\nprint(\"\\nExport complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Statistical Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reward_col:\n",
    "    print(\"=\"*80)\n",
    "    print(\"STATISTICAL ANALYSIS: HYPOTHESIS TESTING\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    # Compare baseline (d=64) to other dimensions\n",
    "    baseline_64 = df[df['embed_dim'] == 64][reward_col].values\n",
    "    \n",
    "    print(\"BASELINE (d=64) COMPARISONS\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for d in [4, 8, 32, 128]:\n",
    "        comparison = df[df['embed_dim'] == d][reward_col].values\n",
    "        \n",
    "        mean_diff = comparison.mean() - baseline_64.mean()\n",
    "        std_diff = np.sqrt(np.std(comparison)**2 + np.std(baseline_64)**2)\n",
    "        pct_diff = (mean_diff / np.abs(baseline_64.mean())) * 100\n",
    "        \n",
    "        print(f\"d={d:3d} vs d=64:\")\n",
    "        print(f\"  Mean:     {comparison.mean():7.3f} (d={d}) vs {baseline_64.mean():7.3f} (d=64)\")\n",
    "        print(f\"  Difference: {mean_diff:+7.3f} ({pct_diff:+6.1f}%)\")\n",
    "        print(f\"  Ratio:     {comparison.mean() / baseline_64.mean():7.3f}x\")\n",
    "        print()\n",
    "    \n",
    "    print(\"\\nPER-AGENT-COUNT ANALYSIS\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for n_agents in sorted(df['num_agents'].unique()):\n",
    "        subset = df[df['num_agents'] == n_agents]\n",
    "        baseline_subset = subset[subset['embed_dim'] == 64]\n",
    "        \n",
    "        if not baseline_subset.empty:\n",
    "            baseline_val = baseline_subset[reward_col].values[0]\n",
    "            print(f\"\\nN={n_agents} agents (baseline d=64: {baseline_val:.3f}):\")\n",
    "            \n",
    "            for d in sorted(subset['embed_dim'].unique()):\n",
    "                if d != 64:\n",
    "                    d_subset = subset[subset['embed_dim'] == d]\n",
    "                    if not d_subset.empty:\n",
    "                        d_val = d_subset[reward_col].values[0]\n",
    "                        pct = (d_val - baseline_val) / np.abs(baseline_val) * 100\n",
    "                        print(f\"  d={d:3d}: {d_val:7.3f} ({pct:+6.1f}%)\")\nelse:\n",
    "    print(\"No reward column for statistical analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Final Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusions = \"\"\"\n",
    "================================================================================\n",
    "FINAL CONCLUSIONS: RENDEZVOUS EMBEDDING DIMENSION SCALING\n",
    "================================================================================\n",
    "\n",
    "RESEARCH QUESTION:\n",
    "Can mean embedding networks achieve competitive performance with reduced embedding\n",
    "dimensions, maintaining the swarm coordination quality of Hüttenrauch baseline while\n",
    "improving computational efficiency?\n",
    "\n",
    "KEY FINDINGS FROM 20-CONFIGURATION MATRIX:\n",
    "\n",
    "1. DIMENSIONAL REDUCTION FEASIBILITY\n",
    "   The analysis shows whether sublinear embedding dimensions (d < 64) can work:\n",
    "   - If d=32 performs within 5% of d=64: dimensional reduction is viable\n",
    "   - If d=8 achieves >90% of d=64 performance: significant compression possible\n",
    "   - If d=4 remains competitive: information requirement is minimal\n",
    "\n",
    "2. SWARM SIZE SCALING EFFECTS\n",
    "   How embedding choice interacts with swarm size:\n",
    "   - N=4 with d=4: Minimal aggregation needed (3 neighbors)\n",
    "   - N=100 with d=4: Severe information bottleneck (99 neighbors -> 4 dims)\n",
    "   - Expected: Gap between d=4 and d=64 increases with N\n",
    "\n",
    "3. SATURATION ANALYSIS\n",
    "   Whether d=128 improves beyond d=64:\n",
    "   - If d=128 ≈ d=64: Saturation reached (no need for >64 dims)\n",
    "   - If d=128 >> d=64: Baseline may be underspecified\n",
    "   - Implications for understanding info requirements of rendezvous task\n",
    "\n",
    "4. CONVERGENCE DYNAMICS\n",
    "   Does embedding dimension affect learning speed?\n",
    "   - Smaller d = faster convergence: regularization effect\n",
    "   - Larger d = faster convergence: more expressive representation\n",
    "   - Relationship guides practical deployment choices\n",
    "\n",
    "COMPARISON TO HÜTTENRAUCH (2019) BASELINE:\n",
    "\n",
    "Hüttenrauch Configuration:\n",
    "  - 20 agents (single training size)\n",
    "  - 64-dimensional embeddings\n",
    "  - Mean aggregation\n",
    "  - TRPO algorithm\n",
    "  - Convergence in ~100-200 iterations\n",
    "\n",
    "This Study Extension:\n",
    "  - 4 training sizes: [4, 16, 50, 100]\n",
    "  - 5 embedding dimensions: [4, 8, 32, 64, 128]\n",
    "  - Same aggregation & algorithm\n",
    "  - Systematic dimensional reduction study\n",
    "\n",
    "THESIS CONTRIBUTION:\n",
    "\n",
    "This analysis contributes to Chapter 4.2 by:\n",
    "  ✓ Validating mean embedding viability across swarm sizes\n",
    "  ✓ Identifying optimal embedding dimension-swarm size combinations\n",
    "  ✓ Quantifying computational savings from dimensional reduction\n",
    "  ✓ Providing evidence for information-theoretic bounds on coordination\n",
    "  ✓ Supporting claims about Hüttenrauch baseline optimality (or lack thereof)\n",
    "\n",
    "PRACTICAL IMPLICATIONS:\n",
    "\n",
    "1. If d=32 matches d=64 performance:\n",
    "   - 2x memory reduction\n",
    "   - Faster inference for real-time control\n",
    "   - Better generalization to new swarm sizes\n",
    "\n",
    "2. If d=8 is competitive:\n",
    "   - 8x memory reduction\n",
    "   - Embedded systems deployment becomes feasible\n",
    "   - Communication bandwidth for multi-robot systems halved\n",
    "\n",
    "3. If performance degrades smoothly:\n",
    "   - Can choose d based on computational budget\n",
    "   - No cliff effects or catastrophic failures expected\n",
    "\n",
    "FUTURE WORK SUGGESTED BY THIS ANALYSIS:\n",
    "\n",
    "1. Multi-seed analysis: Extend d=4 and d=128 configs with seeds [123, 456]\n",
    "2. Generalization testing: Train on one swarm size, test on others\n",
    "3. Attention-based aggregation: Compare to mean embedding\n",
    "4. Architecture ablations: phi_layers, activation functions, etc.\n",
    "\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\nprint(conclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\nprint(\"NOTEBOOK ANALYSIS COMPLETE\")\nprint(\"=\"*80)\nprint()\nprint(\"Generated visualizations:\")\nprint(\"  1. rendezvous_heatmaps.png\")\nprint(\"  2. dimensional_reduction_analysis.png\")\nprint(\"  3. scalability_analysis.png\")\nprint(\"  4. learning_curves_representative.png\")\nprint(\"  5. saturation_analysis.png\")\nprint(\"  6. convergence_analysis.png\")\nprint()\nprint(\"Exported data:\")\nprint(\"  1. rendezvous_scaling_results.csv\")\nprint(\"  2. rendezvous_convergence_analysis.csv\")\nprint()\nprint(\"Summary: 20 experiments analyzed across 4 agent counts and 5 embedding dimensions\")\nprint(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
